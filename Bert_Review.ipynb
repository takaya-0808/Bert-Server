{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERRT-Review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VWiPHuS2aD0"
      },
      "source": [
        "# Bertを利用した利用したReview分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsTb0Ukn26Km"
      },
      "source": [
        "## TenosrflowををImport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZEfxihA37dp"
      },
      "source": [
        "!pip install transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkU1wY9Y2RTk"
      },
      "source": [
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIa9jSXXPns"
      },
      "source": [
        "transformers "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1hmK--k5j0w"
      },
      "source": [
        "## データを構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPETwvSX71zv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIxckFbChN1"
      },
      "source": [
        "ls drive/MyDrive/研究/DialogueAct-Prediction/work/Bert-Twitter/review_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd5fDsNK72Mr"
      },
      "source": [
        "text_path = \"drive/MyDrive/研究/DialogueAct-Prediction/work/Bert-Twitter/data/text/\"\n",
        "label_path = \"drive/MyDrive/研究/DialogueAct-Prediction/work/Bert-Twitter/data/label/\"\n",
        "\n",
        "import glob\n",
        "dir_text_path = glob.glob(text_path+\"*.txt\")\n",
        "dir_label_path = glob.glob(label_path+\"*.txt\")\n",
        "\n",
        "dir_label_path.sort()\n",
        "dir_text_path.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIENXwq18q-D"
      },
      "source": [
        "texts=[0]*len(dir_text_path)\n",
        "labels=[0]*len(dir_label_path)\n",
        "for idx, path in enumerate(dir_text_path):\n",
        "  with open(path) as f:\n",
        "    l = f.read().split(\"', '\")\n",
        "  texts[idx] = l\n",
        "\n",
        "for idx, path in enumerate(dir_label_path):\n",
        "  with open(path) as f:\n",
        "    l = f.read().split(\"\\n\")\n",
        "  labels[idx] = l[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPga56ylNdnQ"
      },
      "source": [
        "for l,t in zip(labels, texts):\n",
        "  if (len(l)!=len(t)):\n",
        "    print(len(l), len(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BValUQB8BRw1"
      },
      "source": [
        "labels_=[]\n",
        "texts_=[]\n",
        "idx=0\n",
        "\n",
        "for i,z in zip(texts, labels):\n",
        "  if len(i) < len(z):\n",
        "    texts_.append(texts[idx])\n",
        "    labels_.append(labels[idx][0:len(i)])\n",
        "  elif len(i) > len(z):\n",
        "    labels_.append(labels[idx])\n",
        "    texts_.append(texts[idx][0:len(z)])\n",
        "  else:\n",
        "    labels_.append(labels[idx])\n",
        "    texts_.append(texts[idx])\n",
        "  idx+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn_dpDqrIbYi"
      },
      "source": [
        "for i,z in zip(labels_, texts_):\n",
        "  print(len(i), len(z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRGl9aYBLN8_"
      },
      "source": [
        "to_vec_labels=[]\n",
        "for label in labels_:\n",
        "  l=[0]*len(label)\n",
        "  for i, v in enumerate(label):\n",
        "    if l=='positive':\n",
        "      l[i] = 1\n",
        "  to_vec_labels.append(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awMjVdHnMJzj"
      },
      "source": [
        "for i,v in enumerate(texts_):\n",
        "  if len(to_vec_labels[i]) != len(v):\n",
        "    print(len(to_vec_labels[i]), len(v))\n",
        "    print(\"miss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0liuV7q3Ni_J"
      },
      "source": [
        "data_texts=[]\n",
        "data_labels=[]\n",
        "\n",
        "for i,v in enumerate(texts_):\n",
        "  for j,r in enumerate(v):\n",
        "    data_texts.append(r)\n",
        "    data_labels.append(to_vec_labels[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpJ5Bst8OMdi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_texts, data_labels, test_size=0.2, random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRuDA33_4arp"
      },
      "source": [
        "## モデル構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKnsp5I83n39"
      },
      "source": [
        "model_name = \"cl-tohoku/bert-base-japanese\"\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eleVnnMD5GM8"
      },
      "source": [
        "### テキストをBERTに適応する変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqwzh4dD44lc"
      },
      "source": [
        "def to_features(texts, max_length):\n",
        "    shape = (len(texts), max_length)\n",
        "    # input_idsやattention_mask, token_type_idsの説明はglossaryに記載(cf. https://huggingface.co/transformers/glossary.html)\n",
        "    input_ids = np.zeros(shape, dtype=\"int32\")\n",
        "    attention_mask = np.zeros(shape, dtype=\"int32\")\n",
        "    token_type_ids = np.zeros(shape, dtype=\"int32\")\n",
        "    for i, text in enumerate(texts):\n",
        "        encoded_dict = tokenizer.encode_plus(text, max_length=max_length, pad_to_max_length=True)\n",
        "        input_ids[i] = encoded_dict[\"input_ids\"]\n",
        "        attention_mask[i] = encoded_dict[\"attention_mask\"]\n",
        "        token_type_ids[i] = encoded_dict[\"token_type_ids\"]\n",
        "    return [input_ids, attention_mask, token_type_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqlUMSbs5SZA"
      },
      "source": [
        "### Bertの単一モデルの構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkk40lhy5Z7C"
      },
      "source": [
        "def build_model(model_name, num_classes, max_length):\n",
        "    input_shape = (max_length, )\n",
        "    input_ids = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
        "    attention_mask = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
        "    token_type_ids = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(model_name)\n",
        "    last_hidden_state, pooled_output = bert_model([input_ids,\n",
        "                                                  attention_mask,\n",
        "                                                  token_type_ids])\n",
        "    \n",
        "    flatten_output = tf.keras.layers.Flatten()(pooled_output)\n",
        "    drop_output = tf.keras.layers.Dropout(0.1)(flatten_output)\n",
        "    output = tf.keras.layers.Dense(64, activation='relu')(drop_output)\n",
        "    drop_output = tf.keras.layers.Dropout(0.1)(output)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(drop_output)\n",
        "    model = tf.keras.Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=[output])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hewDGk-6K8PM"
      },
      "source": [
        "### データセット/モデル構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJOeRiaK5h0Z"
      },
      "source": [
        "num_classes = 2\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "epochs = 30\n",
        "\n",
        "x_train = to_features(X_train, max_length)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icqJycxgeMy"
      },
      "source": [
        "model = build_model(model_name, num_classes=num_classes, max_length=max_length)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLohcyrDK3o4"
      },
      "source": [
        "### モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oK3g8kEQK2LM"
      },
      "source": [
        "# 訓練\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8d7hymOicPm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}